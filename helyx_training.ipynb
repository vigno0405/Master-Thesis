{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ncRoLI6q1YJ-"
   },
   "source": [
    "# Master Thesis - Vignoli Lorenzo\n",
    "\n",
    "---\n",
    "\n",
    "## üêô Helyx training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uzh8DWZY1YKD"
   },
   "source": [
    "## ‚öôÔ∏è Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 36653,
     "status": "ok",
     "timestamp": 1743345202821,
     "user": {
      "displayName": "lorenzo vignoli",
      "userId": "18072656013570133222"
     },
     "user_tz": -120
    },
    "id": "ugDlijph1YKE",
    "outputId": "ff93d924-37f1-4531-977b-b19be0b10e53"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Libraries\n",
    "import os\n",
    "import glob\n",
    "import random\n",
    "import warnings\n",
    "import numpy as np # type: ignore\n",
    "from PIL import Image # type: ignore\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import train_test_split # type: ignore\n",
    "\n",
    "import torch # type: ignore\n",
    "import torch.nn as nn # type: ignore\n",
    "import torch.optim as optim # type: ignore\n",
    "from torch.utils.data import Dataset, DataLoader # type: ignore\n",
    "from torchvision import models, transforms # type: ignore\n",
    "import torch.nn.functional as F # type: ignore\n",
    "import shutil\n",
    "import plotly.graph_objects as go # type: ignore\n",
    "from torch.optim.lr_scheduler import SequentialLR, LinearLR, CosineAnnealingLR, ReduceLROnPlateau # type: ignore\n",
    "import torchvision.transforms as T\n",
    "\n",
    "import matplotlib.pyplot as plt # type: ignore\n",
    "import random\n",
    "import sys\n",
    "from torch.amp import GradScaler, autocast # type: ignore\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = False\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5AOg0kEN1YKH"
   },
   "source": [
    "## ‚è≥ Load and process the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1743345202822,
     "user": {
      "displayName": "lorenzo vignoli",
      "userId": "18072656013570133222"
     },
     "user_tz": -120
    },
    "id": "sK9bmMZV1YKH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Processing Dataset1.pt...\n",
      "Progress: 2.61%"
     ]
    }
   ],
   "source": [
    "# Augmentations\n",
    "blur = T.GaussianBlur(kernel_size=5, sigma=(0.1, 1.5))\n",
    "to_pil = T.ToPILImage()\n",
    "to_tensor = T.ToTensor()\n",
    "\n",
    "# Add small noise to label\n",
    "def add_label_noise(label_tensor, std=0.005):\n",
    "    noise = torch.randn_like(label_tensor) * std\n",
    "    return label_tensor + noise\n",
    "\n",
    "# Add small Gaussian noise to image\n",
    "def add_image_noise(image_tensor, std=0.01):\n",
    "    noise = torch.randn_like(image_tensor) * std\n",
    "    noisy = image_tensor + noise\n",
    "    return torch.clamp(noisy, 0.0, 1.0)\n",
    "\n",
    "if True:\n",
    "\n",
    "    for split in [\"train\", \"val\", \"test\"]:\n",
    "        shutil.rmtree(f\"images/{split}\", ignore_errors=True)\n",
    "        shutil.rmtree(f\"labels/{split}\", ignore_errors=True)\n",
    "        shutil.rmtree(f\"DELTAL/{split}\", ignore_errors=True)\n",
    "        os.makedirs(f\"images/{split}\", exist_ok=True)\n",
    "        os.makedirs(f\"labels/{split}\", exist_ok=True)\n",
    "        os.makedirs(f\"DELTAL/{split}\", exist_ok=True)\n",
    "\n",
    "    dataset_files = sorted(glob.glob(\"Dataset*.pt\"))\n",
    "    total_originals = sum([len(torch.load(f)[\"X_images\"]) for f in dataset_files])\n",
    "    all_indices = np.arange(total_originals)\n",
    "\n",
    "    train_idx, temp_idx = train_test_split(all_indices, test_size=0.15, random_state=seed)\n",
    "    val_idx, test_idx = train_test_split(temp_idx, test_size=1/3, random_state=seed)\n",
    "\n",
    "    split_map = np.full(total_originals, \"\", dtype=object)\n",
    "    split_map[train_idx] = \"train\"\n",
    "    split_map[val_idx] = \"val\"\n",
    "    split_map[test_idx] = \"test\"\n",
    "\n",
    "    global_index = {\n",
    "        \"train\": 0,\n",
    "        \"val\": 0,\n",
    "        \"test\": 0\n",
    "    }\n",
    "\n",
    "    current_idx = 0\n",
    "\n",
    "    for file in dataset_files:\n",
    "\n",
    "        print(f\"\\n Processing {file}...\")\n",
    "        data = torch.load(file)\n",
    "        X_images = data[\"X_images\"]\n",
    "        y = data[\"y\"]\n",
    "        X_DELTAL = data[\"X_DELTAL\"]\n",
    "\n",
    "        for i in range(len(X_images)):\n",
    "\n",
    "            split = split_map[current_idx]\n",
    "            assert split in {\"train\", \"val\", \"test\"}\n",
    "\n",
    "            image_tensor = X_images[i]\n",
    "            label_tensor = y[i]\n",
    "            deltal_tensor = X_DELTAL[i]\n",
    "\n",
    "            idx_str = f\"{global_index[split]:06d}\"\n",
    "\n",
    "            # Original\n",
    "            torch.save(image_tensor, f\"images/{split}/img_{idx_str}.pt\")\n",
    "            torch.save(label_tensor, f\"labels/{split}/label_{idx_str}.pt\")\n",
    "            torch.save(deltal_tensor, f\"DELTAL/{split}/deltal_{idx_str}.pt\")\n",
    "\n",
    "            # Augmented only for training set\n",
    "            if split == \"train\":\n",
    "                # Blur + Gaussian noise on image\n",
    "                pil_image = to_pil(image_tensor)\n",
    "                blurred_tensor = to_tensor(blur(pil_image))\n",
    "                noisy_blurred = add_image_noise(blurred_tensor, std=0.01)\n",
    "\n",
    "                # Noise on label\n",
    "                noisy_label = add_label_noise(label_tensor, std=0.005)\n",
    "\n",
    "                # Save augmented copy\n",
    "                torch.save(noisy_blurred, f\"images/{split}/img_{idx_str}_aug.pt\")\n",
    "                torch.save(noisy_label, f\"labels/{split}/label_{idx_str}_aug.pt\")\n",
    "                torch.save(deltal_tensor, f\"DELTAL/{split}/deltal_{idx_str}_aug.pt\")\n",
    "\n",
    "            global_index[split] = global_index[split] + 1\n",
    "            current_idx += 1\n",
    "\n",
    "            percent = (current_idx / total_originals) * 100\n",
    "            sys.stdout.write(f\"\\rProgress: {percent:.2f}%\")\n",
    "            sys.stdout.flush()\n",
    "\n",
    "        del X_images\n",
    "        del y\n",
    "        del X_DELTAL\n",
    "\n",
    "    print(\"\\n Finished dataset generation.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True:\n",
    "    label_paths = sorted(glob.glob(\"labels/train/*.pt\"))\n",
    "    all_labels = torch.stack([torch.load(p).float() for p in label_paths])\n",
    "    mean = all_labels.mean(dim=0)\n",
    "    std = all_labels.std(dim=0)\n",
    "    torch.save({'mean': mean, 'std': std}, 'label_stats.pt')\n",
    "\n",
    "    del mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageRegressionDataset(Dataset):\n",
    "    def __init__(self, image_paths, label_paths):\n",
    "        self.image_paths = image_paths\n",
    "        self.label_paths = label_paths\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        image = torch.load(self.image_paths[idx]).float()   # [C, H, W] in [0, 255]\n",
    "        label = torch.load(self.label_paths[idx]).float()   # [6]\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load sorted image and label paths\n",
    "def get_paths(split):\n",
    "    image_dir = os.path.join(\"images\", split)\n",
    "    label_dir = os.path.join(\"labels\", split)\n",
    "    image_paths = sorted([os.path.join(image_dir, f) for f in os.listdir(image_dir) if f.endswith(\".pt\")])\n",
    "    label_paths = sorted([os.path.join(label_dir, f) for f in os.listdir(label_dir) if f.endswith(\".pt\")])\n",
    "    assert len(image_paths) == len(label_paths)\n",
    "    return image_paths, label_paths\n",
    "\n",
    "# Get paths for each split\n",
    "train_img, train_lbl = get_paths(\"train\")\n",
    "val_img, val_lbl = get_paths(\"val\")\n",
    "test_img, test_lbl = get_paths(\"test\")\n",
    "\n",
    "# Dataset dimensions\n",
    "print(f\"Processed: \\n {len(train_img)} training images \\n {len(val_img)} validation images \\n {len(test_img)} test images\")\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = ImageRegressionDataset(train_img, train_lbl)\n",
    "val_dataset = ImageRegressionDataset(val_img, val_lbl)\n",
    "test_dataset = ImageRegressionDataset(test_img, test_lbl)\n",
    "\n",
    "# Create dataloaders (ottimizzati)\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True,\n",
    "                          num_workers=12, pin_memory=True, persistent_workers=True)\n",
    "\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False,\n",
    "                        num_workers=12, pin_memory=True, persistent_workers=True)\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False,\n",
    "                         num_workers=12, pin_memory=True, persistent_workers=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kke1mM381YKK"
   },
   "source": [
    "## ‚öì Network definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Markers(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def rgb_to_hsv(self, x):\n",
    "        r, g, b = x[:, 0], x[:, 1], x[:, 2]\n",
    "        maxc, _ = x.max(dim=1)\n",
    "        minc, _ = x.min(dim=1)\n",
    "        v = maxc\n",
    "        eps = 1e-8\n",
    "\n",
    "        deltac = maxc - minc\n",
    "        s = deltac / (maxc + eps)\n",
    "        s[maxc == 0] = 0\n",
    "\n",
    "        rc = (maxc - r) / (deltac + eps)\n",
    "        gc = (maxc - g) / (deltac + eps)\n",
    "        bc = (maxc - b) / (deltac + eps)\n",
    "\n",
    "        h = torch.zeros_like(maxc)\n",
    "        h[maxc == r] = (bc - gc)[maxc == r]\n",
    "        h[maxc == g] = 2.0 + (rc - bc)[maxc == g]\n",
    "        h[maxc == b] = 4.0 + (gc - rc)[maxc == b]\n",
    "        h = (h / 6.0) % 1.0\n",
    "        h[deltac == 0] = 0.0\n",
    "\n",
    "        return torch.stack([h, s, v], dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        hsv = self.rgb_to_hsv(x)\n",
    "        h, s, v = hsv[:, 0], hsv[:, 1], hsv[:, 2]\n",
    "\n",
    "        green = ((h > 0.25) & (h < 0.45) & (s > 0.3) & (v > 0.2)).unsqueeze(1).float()\n",
    "        black = (v < 0.3).unsqueeze(1).float()\n",
    "\n",
    "        return torch.cat([black, green, x], dim=1)     # if 2 markers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a random image\n",
    "paths = sorted(glob.glob(\"images/train/*.pt\"))\n",
    "path = random.choice(paths)\n",
    "image = torch.load(path).float() / 255  # [3, H, W]\n",
    "\n",
    "# Apply markers\n",
    "markers = Markers()\n",
    "filtered = markers(image.unsqueeze(0))[0]  # [2, H, W]\n",
    "\n",
    "# Visualize\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow((image*255).permute(1, 2, 0).byte())\n",
    "plt.title(\"Original RGB\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(filtered[0].cpu(), cmap=\"gray\")\n",
    "plt.title(\"Black Marker\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(filtered[1].cpu(), cmap=\"gray\")\n",
    "plt.title(\"Green Marker\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, stack=1, dropout=True):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        for i in range(stack):\n",
    "            if i == 0:\n",
    "                conv_in = in_channels\n",
    "            else:\n",
    "                conv_in = out_channels\n",
    "            layers.append(nn.Conv2d(conv_in, out_channels, kernel_size=kernel_size, padding=kernel_size // 2))\n",
    "            layers.append(nn.BatchNorm2d(out_channels))\n",
    "            layers.append(nn.ReLU(inplace=True))\n",
    "            if dropout:\n",
    "                layers.append(nn.Dropout2d(0.05))\n",
    "        self.blocks = nn.Sequential(*layers)\n",
    "\n",
    "        self.skip_adjust = nn.Identity()\n",
    "        if in_channels != out_channels:\n",
    "            self.skip_adjust = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = self.skip_adjust(x)\n",
    "        out = self.blocks(x)\n",
    "        out += identity\n",
    "        return F.relu(out, inplace=True)\n",
    "\n",
    "class DecoderBlock(nn.Module):\n",
    "    def __init__(self, in_channels, skip_channels, out_channels, stack=2):\n",
    "        super().__init__()\n",
    "        self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=False)\n",
    "        self.res = ResidualBlock(in_channels + skip_channels, out_channels, stack=stack)\n",
    "\n",
    "    def forward(self, x, skip):\n",
    "        x = self.up(x)\n",
    "        if x.shape[-2:] != skip.shape[-2:]:\n",
    "            diff_h = skip.shape[-2] - x.shape[-2]\n",
    "            diff_w = skip.shape[-1] - x.shape[-1]\n",
    "            skip = skip[:, :, diff_h // 2: diff_h // 2 + x.shape[-2],\n",
    "                              diff_w // 2: diff_w // 2 + x.shape[-1]]\n",
    "        x = torch.cat([x, skip], dim=1)\n",
    "        return self.res(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1743345225838,
     "user": {
      "displayName": "lorenzo vignoli",
      "userId": "18072656013570133222"
     },
     "user_tz": -120
    },
    "id": "kNob-BPJ1YKM"
   },
   "outputs": [],
   "source": [
    "class NetCamera(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.markers = Markers()\n",
    "\n",
    "        self.enc1 = ResidualBlock(5, 8, stack=3)\n",
    "        self.enc2 = ResidualBlock(8, 16, stack=3)\n",
    "        self.enc3 = ResidualBlock(16, 32, stack=3)\n",
    "        self.enc4 = ResidualBlock(32, 64, stack=3)\n",
    "        self.enc5 = ResidualBlock(64, 128, stack=3)\n",
    "\n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "\n",
    "        self.bottleneck = ResidualBlock(128, 256, stack=3)\n",
    "\n",
    "        self.dec1 = DecoderBlock(256, 128, 128, stack=3)\n",
    "        self.dec2 = DecoderBlock(128, 64, 64, stack=3)\n",
    "        self.dec3 = DecoderBlock(64, 32, 32, stack=3)\n",
    "        self.dec4 = DecoderBlock(32, 16, 16, stack=3)\n",
    "        self.dec5 = DecoderBlock(16, 8, 8, stack=3)\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d((15, 20)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(8 * 15 * 20, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 6)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x / 255.0\n",
    "        x = self.markers(x)\n",
    "\n",
    "        x1 = self.enc1(x)\n",
    "        x2 = self.enc2(self.pool(x1))\n",
    "        x3 = self.enc3(self.pool(x2))\n",
    "        x4 = self.enc4(self.pool(x3))\n",
    "        x5 = self.enc5(self.pool(x4))\n",
    "\n",
    "        x = self.bottleneck(self.pool(x5))\n",
    "\n",
    "        x = self.dec1(x, x5)\n",
    "        x = self.dec2(x, x4)\n",
    "        x = self.dec3(x, x3)\n",
    "        x = self.dec4(x, x2)\n",
    "        x = self.dec5(x, x1)\n",
    "\n",
    "        x = self.fc(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KDp2hJNe1YKM"
   },
   "source": [
    "## üòì Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NetCamera().to(device)\n",
    "\n",
    "# Check the number of parameters\n",
    "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Total trainable parameters: {total_params:,}\")\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3, weight_decay=8e-6)\n",
    "\n",
    "# Learning rate management\n",
    "scheduler = LinearLR(optimizer, start_factor = 1e-3, end_factor = 1.0, total_iters = 10)\n",
    "plateau_scheduler = ReduceLROnPlateau(optimizer, mode = 'min', factor = 0.75, patience=25, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_val_loss = float('inf')\n",
    "patience = 100\n",
    "counter = 0\n",
    "\n",
    "# Normalization parameters\n",
    "stats = torch.load(\"label_stats.pt\")\n",
    "mean = stats['mean'].to(device)\n",
    "std = stats['std'].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_train = []\n",
    "history_val = []\n",
    "\n",
    "scaler = GradScaler(device='cuda')\n",
    "\n",
    "accumulation_steps = 200\n",
    "optimizer.zero_grad()\n",
    "epochs = 1000\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    train_losses = []\n",
    "    total_batches = len(train_loader)\n",
    "\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        with autocast(device_type='cuda'):\n",
    "            labels_norm = (labels - mean) / std\n",
    "            preds = model(images)\n",
    "            loss = criterion(preds, labels_norm)\n",
    "\n",
    "        loss = loss / accumulation_steps\n",
    "        scaler.scale(loss).backward()\n",
    "\n",
    "        train_losses.append(loss.item() * accumulation_steps)\n",
    "\n",
    "        progress = (i + 1) / total_batches * 100\n",
    "        sys.stdout.write(f\"\\rEpoch {epoch + 1}: {progress:.1f}%\")\n",
    "        sys.stdout.flush()\n",
    "\n",
    "        # Perform gradient update at the end of the accumulation steps\n",
    "        if (i + 1) % accumulation_steps == 0 or (i + 1) == total_batches:\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "    model.eval()\n",
    "    val_losses = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            with autocast(device_type='cuda'):\n",
    "                labels_norm = (labels - mean) / std\n",
    "                preds = model(images)\n",
    "                loss = criterion(preds, labels_norm)\n",
    "\n",
    "            val_losses.append(loss.item())\n",
    "\n",
    "    avg_train_loss = np.mean(train_losses)\n",
    "    avg_val_loss = np.mean(val_losses)\n",
    "    scheduler.step()\n",
    "\n",
    "    plateau_scheduler.step(avg_val_loss)\n",
    "    history_train.append(avg_train_loss)\n",
    "    history_val.append(avg_val_loss)\n",
    "\n",
    "    sys.stdout.write(\"\\r\")\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    print(f\"Epoch {epoch + 1} | Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f} | LR: {current_lr:.6f}\")\n",
    "\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        torch.save(model, \"helyx_model_normalized.pt\")\n",
    "        counter = 0\n",
    "    else:\n",
    "        counter += 1\n",
    "        if counter >= patience:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break\n",
    "\n",
    "del model\n",
    "del stats\n",
    "del mean\n",
    "del std\n",
    "del optimizer\n",
    "del scheduler\n",
    "del plateau_scheduler\n",
    "del scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2wqfikoy1YKN"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(history_train, label='Train Loss')\n",
    "plt.plot(history_val, label='Val Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training vs Validation Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenormalizedModel(nn.Module):\n",
    "    def __init__(self, base_model, mean, std):\n",
    "        super().__init__()\n",
    "        self.base_model = base_model\n",
    "        self.register_buffer(\"mean\", mean)\n",
    "        self.register_buffer(\"std\", std)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.base_model(x)\n",
    "        return out * self.std + self.mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(\"helyx_model_normalized.pt\")\n",
    "stats = torch.load(\"label_stats.pt\")\n",
    "\n",
    "# Model and parameters\n",
    "model = model.to(device)\n",
    "mean = stats['mean'].to(device)\n",
    "std = stats['std'].to(device)\n",
    "\n",
    "# Save final model\n",
    "final_model = DenormalizedModel(model, mean, std)\n",
    "torch.save(final_model, \"helyx_model.pt\")\n",
    "\n",
    "del final_model\n",
    "del stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oror0-Yt1YKN"
   },
   "source": [
    "## ‚è∞ Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZwjA5m9n1YKN"
   },
   "outputs": [],
   "source": [
    "# Load full model\n",
    "model = torch.load(\"helyx_model.pt\")\n",
    "model_normalized = torch.load(\"helyx_model_normalized.pt\")\n",
    "stats = torch.load(\"label_stats.pt\")\n",
    "mean = stats['mean'].to(device)\n",
    "std = stats['std'].to(device)\n",
    "model = model.to(device)\n",
    "model_normalized = model_normalized.to(device)\n",
    "model.eval()\n",
    "model_normalized.eval()\n",
    "\n",
    "all_preds = []\n",
    "all_preds_normalized = []\n",
    "all_labels = []\n",
    "all_labels_normalized = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        labels_normalized = (labels - mean) / std\n",
    "\n",
    "        preds = model(images)\n",
    "        preds_normalized = model_normalized(images)\n",
    "        all_preds.append(preds.cpu().numpy())\n",
    "        all_labels.append(labels.cpu().numpy())\n",
    "        all_preds_normalized.append(preds_normalized.cpu().numpy())\n",
    "        all_labels_normalized.append(labels_normalized.cpu().numpy())\n",
    "        del images, labels, preds, preds_normalized\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "all_preds = np.concatenate(all_preds, axis=0)\n",
    "all_labels = np.concatenate(all_labels, axis=0)\n",
    "all_preds_normalized = np.concatenate(all_preds_normalized, axis=0)\n",
    "all_labels_normalized = np.concatenate(all_labels_normalized, axis=0)\n",
    "\n",
    "mse = np.mean((all_preds - all_labels) ** 2)\n",
    "mse_normalized = np.mean((all_preds_normalized - all_labels_normalized) ** 2)\n",
    "print(f\"Test MSE - normalized: {mse_normalized:.4f}\")\n",
    "print(f\"Test MSE: {mse:.4f}\")\n",
    "\n",
    "all_preds[:, 3:] = np.rad2deg(all_preds[:, 3:])\n",
    "all_labels[:, 3:] = np.rad2deg(all_labels[:, 3:])\n",
    "\n",
    "param_names = ['X [mm]', 'Y [mm]', 'Z [mm]', 'Yaw [¬∞]', 'Pitch [¬∞]', 'Roll [¬∞]']\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 8))\n",
    "\n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "    mae = np.mean(np.abs(all_preds[:, i] - all_labels[:, i]))  # Calculate MAE\n",
    "    ax.plot(all_labels[:, i], label='True', alpha=0.7)\n",
    "    ax.plot(all_preds[:, i], label='Pred', alpha=0.7)\n",
    "    ax.set_title(f\"{param_names[i]} - MAE: {mae:.2f}\")\n",
    "    ax.grid(True)\n",
    "\n",
    "axes[0, 0].legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "soft_robot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
